\chapter{Studio e ricerca preliminare}
\label{cap:analisi preliminare}

\intro{In questo capitolo verranno illustrate le varie metodologie individuate per poter rendere di maggiore qualità le risposte fornite dal RALM e le diverse tecnologie utlizzate} \\

\section{Analisi dei requisiti}
I documenti, prima di essere passati al RALM, devono essere rielaborati in modo tale da renderli più "comprensibili".
Il contenuto viene quindi diviso in porzioni di testo più piccole chiamate "chunk". A ogni domanda vengono analizzati tutti i 
diversi chunk e ad ognuno di essi viene assegnato uno "score" che stabilirà quale di loro ha il contenuto più adatto da cui 
poter ricavare la risposta.
I problemi principali affrontati in questo stage sono stati i seguenti:
\begin{itemize}
    \item Linearizzazione delle tabelle: gli strumenti utilizzati per estrapolare il testo non permettevano di linearizzare 
    la tabella in una maniera tale da renderla "leggibile" al RALM;
    \item Individuazione della struttura del contenuto e suddivisione sensata all'interno dei chunk: 
    inizialmente il testo veniva separato tramite una sliding window che consentiva di ripetere l'informazione in più chunk in modo tale da non perdere 
    il significato di alcune frasi.
    Con questa metodologia però si rischia di accorpare nello stesso chunk informazioni appartenenti a diversi paragrafi e che, quindi, potrebbero essere incoerenti fra loro.
\end{itemize}

I fomrmati dei file considerati in questo stage sono stati i seguenti:
\begin{itemize}
    \item Pdf;
    \item Docx;
    \item HTML.
\end{itemize}

\subsection{Table Question Answering}
Nel Table Question Answering (TQA) le domande poste dall'utente cercano di avere una risposta precisa con i dati ricavati da delle tabelle.
L'obiettivo è quello di migliorare l'accesso e la comprensione delle informazioni strutturate contenute nelle tabelle.

\subsubsection{Linearizzazione delle tabelle}
Una tabella può assumere moltissime strutture e per questo abbiamo deciso di considerare solamente le tabelle che avessero come prima riga 
un'intesazione orizzontale e nelle righe successive i vari dati.

\begin{table}[H]
    \centering
    \begin{tabular}{|p{3cm} |p{2cm} |p{2cm}| p{2cm}| p{2cm}|}
        \hline
        Cibo & Quantità & Energia(KCal) & Carboidrati(g) & Proteine(g) \\
        \hline
        Pennette rigate & 100g & 359 & 71 & 13 \\
        \hline
        Latte & 100ml & 47 & 4,9 & 3,2 \\
        \hline
        Banana & 100g & 89 & 23 & 1,1 \\
        \hline
    \end{tabular}
    \caption{Esempio di tabella presa in considerazione (valori approssimativi)}
    \label{tab:esempio-cibo}
\end{table}
\noindent Come specificato precedentemente le tabelle al momento dell'estrazione venivano linearizzate 
perdendo alcune informazioni necessarie per la lettura effettuata dal RALM. 

\noindent Per esempio la tabella \ref{tab:esempio-cibo} verrebbe linearizzata in questa maniera:
\begin{tcolorbox}[colback=white, colframe=black]
    Cibo Quantità Energia(KCal) Carboidrati(g) Proteine(g) Pennette rigate  100g  359  71  13 Latte 100ml 47 4,9 3,2 Banana  100g 89 23 1,1
\end{tcolorbox}
\noindent La tabella linearizzata perde quindi le informazioni sulla struttura e come risultato abbiamo una serie di valori posti senza avere troppo senso in fase di lettura per un RALM. \\

\noindent Dopo un attenta ricerca effettuata su vari documenti scientifici sono riuscito ad individuare un modo semplice ed efficace per mantenere 
l'informazione nella tabella linearizzata e la sua struttura:
\begin{itemize}
    \item All'inizio di ogni riga viene scritto "Riga n->" dove n sta per il numero della riga;
    \item Per ogni cella presente nella tabella vengono concatenati il valore dell'intestazione della colonna dov'è presente il valore e il valore della cella separati dal carattere ":";
    \item Ogni cella viene poi separata dall'altra con il carattere "|".
\end{itemize} 

Quindi la tabella \ref{tab:esempio-cibo} viene linearizzata in questo modo:
\begin{tcolorbox}[colback=white, colframe=black]
    Riga0->Cibo: Pennette rigate|Quantità:100g|Energia(KCal):359|Carboidrati(g): \\
    71|Proteine(g):13| Riga1->Cibo: Latte|Quantità:100ml|Energia(KCal):47| \\
    Carboidrati(g):4,9|Proteine(g):3,2| Riga2->Cibo: Banana|Quantità:100g \\
    |Energia(KCal):89|Carboidrati(g):23|Proteine(g):1,1|
\end{tcolorbox}

\subsection{Chunking}

\subsubsection{Recupero delle informazioni}
\paragraph{\gls{BM25}}
BM25 è una ranking function usata dai motori di ricerca (nel mio caso \nameref{subsec:weav}), è un algoritmo di tipo \emph{\gls{Bag-of-Words}}\glsfirstoccur e calcola un punteggio per ogni chunk
presente in base alla frequenza di vari termini presenti nella query di ricerca. 

\paragraph{Vector search}
Tramite la vector search vengono generate rappresentazioni vettoriali dei dati ed è possibile calcolare la similarità tra i vettori.
Per poter riconoscere il vero significato attribuito ad una parola i chunk vengono suddivisi a loro volta in token.
Il token indica una singola unità linguistica o comunque un elemento individuale all'interno di un testo e può rappresentare per esempio una parola, un simbolo di punteggiatura o anche una parte di una parola.
Grazie a questi token è possibile calcolare la distanza tra i vettori tramite.
Il tipo di distanza utiilizzata in questo progetto è stata la "Cosine Distance"
% spiegare la cosine

\paragraph{Ricerca ibridia}
Il tipo di ricerca applicata in Weaviate per questo progetto è stata la ricerca ibridia che sfrutta sia BM25 che la Vector search per poter stabilire un punteggio per i chunk.


