\chapter{Studio e ricerca preliminare}
\label{cap:analisi preliminare}

\intro{In questo capitolo verranno illustrate nel dettaglio le varie metodologie individuate per poter rendere di maggiore qualità le risposte fornite dal RALM tramite il raggiungimento dei diversi obiettivi.} \\

\section{Analisi dei requisiti}
I documenti, prima di essere passati al RALM, devono essere rielaborati in modo tale da renderli più comprensibili al modello.
I problemi principali affrontati, e quindi i requisiti, in questo stage sono stati i seguenti:
\begin{itemize}
    \item Linearizzazione delle tabelle: gli strumenti utilizzati per estrapolare il testo non permettevano di linearizzare 
    la tabella in una maniera tale da renderla "leggibile" al RALM;
    \item Chunking: il contenuto viene diviso in porzioni di testo più piccole chiamate \emph{chunk} per poter essere interpretate dal modello. A ogni domanda vengono analizzati tutti i 
    diversi chunk e ad ognuno di essi viene assegnato uno \emph{score} che stabilirà quale di loro ha il contenuto più adatto da cui poter ricavare la risposta. 
    \noindent C'è bisogno quindi di individuare la struttura del contenuto e suddividerlo in modo sensato all'interno dei chunk.
    Inizialmente il testo veniva separato tramite una sliding window che consentiva di formare dei chunk con la parte finale del chunk precedente e la parte successiva presente nel documento in modo tale da non perdere in significato di alcune frasi evetualemente spezzate in punti non adatti.
    \noindent Con questa metodologia però si rischia di accorpare nello stesso chunk informazioni appartenenti a diversi paragrafi e che, quindi, potrebbero essere incoerenti fra loro.
\end{itemize}

I fomrmati dei file considerati in questo stage sono stati i seguenti:
\begin{itemize}
    \item Pdf;
    \item Docx;
    \item HTML.
\end{itemize}

\section{Ricerca e studio preliminare}
\subsection{Table Question Answering}
Nel Table Question Answering (TQA) le domande poste dall'utente cercano di avere una risposta precisa con i dati ricavati da delle tabelle.
L'obiettivo è quello di migliorare l'accesso e la comprensione delle informazioni strutturate contenute nelle tabelle.

\subsubsection{Linearizzazione delle tabelle}
\label{subsubsec-lin-tab}
Una tabella può assumere moltissime strutture e per questo abbiamo deciso di considerare solamente le tabelle che avessero come prima riga 
un'intesazione orizzontale e nelle righe successive i vari dati.

\begin{table}[H]
    \centering
    \begin{tabular}{|p{3cm} |p{2cm} |p{2cm}| p{2cm}| p{2cm}|}
        \hline
        Cibo & Quantità & Energia(KCal) & Carboidrati(g) & Proteine(g) \\
        \hline
        Pennette rigate & 100g & 359 & 71 & 13 \\
        \hline
        Latte & 100ml & 47 & 4,9 & 3,2 \\
        \hline
        Banana & 100g & 89 & 23 & 1,1 \\
        \hline
    \end{tabular}
    \caption{Esempio di tabella presa in considerazione (valori approssimativi)}
    \label{tab:esempio-cibo}
\end{table}
\noindent Come specificato precedentemente le tabelle al momento dell'estrazione venivano linearizzate 
perdendo alcune informazioni necessarie per la lettura effettuata dal RALM. 

\noindent Per esempio la tabella \ref{tab:esempio-cibo} verrebbe linearizzata in questa maniera:
\begin{tcolorbox}[colback=white, colframe=black]
    Cibo Quantità Energia(KCal) Carboidrati(g) Proteine(g) Pennette rigate  100g  359  71  13 Latte 100ml 47 4,9 3,2 Banana  100g 89 23 1,1
\end{tcolorbox}
\noindent La tabella linearizzata perde quindi le informazioni sulla struttura e come risultato abbiamo una serie di valori posti senza avere troppo senso in fase di lettura per un RALM. \\

\noindent Dopo un attenta ricerca effettuata su vari documenti scientifici sono riuscito ad individuare un modo semplice ed efficace per mantenere 
l'informazione nella tabella linearizzata e la sua struttura:
\begin{itemize}
    \item All'inizio di ogni riga viene scritto "Riga n->" dove n sta per il numero della riga;
    \item Per ogni cella presente nella tabella vengono concatenati il valore dell'intestazione della colonna dov'è presente il valore e il valore della cella separati dal carattere ":";
    \item Ogni cella viene poi separata dall'altra con il carattere "|".
\end{itemize} 

Quindi la tabella \ref{tab:esempio-cibo} viene linearizzata in questo modo:
\begin{tcolorbox}[colback=white, colframe=black]
    Riga0->Cibo: Pennette rigate|Quantità:100g|Energia(KCal):359|Carboidrati(g): \\
    71|Proteine(g):13| Riga1->Cibo: Latte|Quantità:100ml|Energia(KCal):47| \\
    Carboidrati(g):4,9|Proteine(g):3,2| Riga2->Cibo: Banana|Quantità:100g \\
    |Energia(KCal):89|Carboidrati(g):23|Proteine(g):1,1|
\end{tcolorbox}

\subsection{Chunking}
\paragraph{Procedimento}
Il \emph{chunking} è il procedimento mediante il quale in contenuto testuale di un documento viene suddiviso in parti più piccole chiamate chunk.
\noindent Per poter fornire una risposta ben strutturata viene utilizzato un \emph{Chat-Completion Model} che riceve in ingresso una richiesta e tramite quest'ultima è in grado di costruire una risposta ben strutturata.
La richiesta è formata dalla domanda dell'utente seguita dai chunk a cui il motore di ricerca ha dato lo score più alto.
Il modello in ingresso può prendere un numero limitato di \emph{token} quindi non gli si può dare l'intero contenuto del documento, ha bisogno di questa suddivisione.

\noindent Per poter capire al meglio il significato delle parole presenti in un determinato contesto è necessario avere spezzare i chunk in \emph{token}.
Il \emph{token} indica una singola unità linguistica o comunque un elemento individuale all'interno di un testo e può rappresentare per esempio una parola, un simbolo di punteggiatura o anche una parte di una parola.
Qui di seguito viene spiegato come il motore di ricerca è in grado di assegnare lo score ai vari chunk e quindi come si riesce a capire quali sono i chunk che come contenuto avranno probabilmente la risposta che si cerca.

\subsubsection{Recupero delle informazioni}
\label{subsubsec:rec-inf}
\paragraph{\gls{BM25}}
BM25 è una ranking function usata dai motori di ricerca (nel mio caso \nameref{subsec:weav}), è un algoritmo di tipo \emph{\gls{Bag-of-Words}}\glsfirstoccur e calcola un punteggio per ogni chunk
presente in base alla frequenza di vari termini presenti nella query di ricerca. 

\paragraph{Vector search}
Tramite la vector search vengono generate rappresentazioni vettoriali dei dati ed è possibile calcolare la similarità tra i vettori.
Per poter riconoscere il vero significato attribuito ad una parola i chunk vengono suddivisi a loro volta in token.
Grazie a questi token è possibile calcolare la distanza tra i vettori tramite.
Il tipo di distanza utilizzata in questo progetto è stata la \emph{Cosine Distance}.

\subparagraph{Cosine similarity}
La \emph{Cosine similarity} misura l'angolo tra due vettori in uno spazio multidimensionale (con l'idea che due vettori simili puntino in direzioni simili).
La cosine similarity e la cosine distance hanno una relazione inversa: all'aumentare della distanza la similarità diminuisce e viceversa.

\noindent Dati due vettori A,B la \emph{cosine similarity} viene calcolata come segue:

\[
\text{Cos(A,B)} = \frac{{\mathbf{A} \cdot \mathbf{B}}}{{\|\mathbf{A}\| \cdot \|\mathbf{B}\|}}    
\]

\[
\text{Cosine distance} = 1-Cos(A,B)
\]

\paragraph{Ricerca ibrida}
Il tipo di ricerca applicata in Weaviate per questo progetto è stata la ricerca ibridia che sfrutta sia BM25 che la \emph{Vector search} per poter stabilire uno score per i chunk.

\subparagraph{\gls{RRF}}
L'RRF score è il calcolo attreverso il quale riusciamo ad avere uno score unico per la ricerca ibrida.
Ad ogni documento viene assegnato un punteggio che equivale alla somma dei reciproci dei suoi piazzamenti nelle varie ranked list ottenute tramite gli altri algoritmi utilizzati nella ricerca.

\[
\text{RFF} = \sum_{d \in D} (\frac{1}{k+r(d)})    
\]

\noindent Per esempio vengono dati tre chunk A, B, C e vengono classificati nella seguente maniera tramite i due ranking algorithm:

\begin{table}[H]
    \centering
    \begin{tabular}{|p{2cm} |p{2cm} |p{2cm}|}
        \hline
        Posizione & BM25 & Vector Search \\
        \hline
        1 & A & B \\
        \hline
        2 & B & C \\
        \hline
        3 & C & A \\
        \hline
    \end{tabular}
    \caption{Esempio di ranking per i documenti A, B, C tramite BM25 e Vector Search}
\end{table}

\noindent Gli RRF score dei documenti A, B, C sono i seguenti:
\begin{table}[H]
    \centering
    \begin{tabular}{|p{3cm} | p{3cm} |}
        \hline
        Chunk & RRF score \\
        \hline
        A & 1/1 + 1/3 = 1.3\\
        \hline
        B & 1/2 + 1/1 = 1.5\\
        \hline
        C & 1/3 + 1/2 = 0.83\\
        \hline
    \end{tabular}
    \caption{Esempio di calcolo del RRF score per i documenti A, B, C}
\end{table}

\noindent In questo esempio abbiamo quindi che il miglior chunk da considerare è il chunk B seguito poi dal chunk A e dal C.




